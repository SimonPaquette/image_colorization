{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSI 4106 - Introduction to Artificial Intelligence - Project W2022\n",
    "\n",
    "### Simon Paquette - spaqu044@uottawa.ca - 300044038\n",
    "\n",
    "### Image Colorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling2D,\n",
    "    ReLU,\n",
    "    RepeatVector,\n",
    "    Reshape,\n",
    "    UpSampling2D,\n",
    "    concatenate,\n",
    ")\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my gpu: GTX1650 4gb\n",
    "import GPUtil\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for i, gpu in enumerate(GPUs):\n",
    "    print(\n",
    "        \"GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%\".format(\n",
    "            i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil * 100\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "SIZE = (WIDTH, HEIGHT)\n",
    "BATCH = 8\n",
    "\n",
    "\n",
    "def make_dir(name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Create and return directory name\n",
    "\n",
    "    Args:\n",
    "        name (str): directory name\n",
    "\n",
    "    Returns:\n",
    "        Path: directory name\n",
    "    \"\"\"\n",
    "    path = Path(name)\n",
    "    if not path.exists():\n",
    "        path.mkdir()\n",
    "    return path\n",
    "\n",
    "\n",
    "IMAGES_DIR = make_dir(\"images\")\n",
    "MODELS_DIR = make_dir(\"models\")\n",
    "LOGS_DIR = make_dir(\"logs\")\n",
    "TMP_DIR = make_dir(\"tmp\")\n",
    "\n",
    "# List of callback to be applied in model.fit()\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    TMP_DIR.joinpath(str(int(time.time()))), verbose=1\n",
    ")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(LOGS_DIR.joinpath(str(int(time.time()))))\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)\n",
    "\n",
    "CALLBACKS = [early_stop, checkpoints, tensorboard, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_log_tmp():\n",
    "    \"\"\"\n",
    "    Delete the files within logs folder (tensorboard log) and tmp folder (model checkpoint)\n",
    "    \"\"\"\n",
    "    logs = list(LOGS_DIR.iterdir())\n",
    "    tmps = list(TMP_DIR.iterdir())\n",
    "    names = logs + tmps\n",
    "    for name in names:\n",
    "        if name.is_dir():\n",
    "            shutil.rmtree(name)\n",
    "        elif name.is_file():\n",
    "            name.unlink()\n",
    "\n",
    "\n",
    "del_log_tmp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Open, resize, convert to LAB, and normalize the image\n",
    "\n",
    "    Args:\n",
    "        image_path (Path): image to be opened\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: L channel and AB channel\n",
    "    \"\"\"\n",
    "    image = cv.imread(str(image_path), cv.IMREAD_COLOR)\n",
    "    image = cv.resize(image, SIZE)\n",
    "    image = image.astype(np.uint8)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2LAB)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0\n",
    "    l, a, b = cv.split(image)\n",
    "    ab = cv.merge([a, b])\n",
    "    return (l, ab)\n",
    "\n",
    "\n",
    "def construct_image(l_channel: np.ndarray, ab_channel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merge LAB, clip, range value between 0-255, and convert to RGB\n",
    "\n",
    "    Args:\n",
    "        l_channel (np.ndarray): L* lightness\n",
    "        ab_channel (np.ndarray): a* green-red && b* yellow-blue\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: RGB image\n",
    "    \"\"\"\n",
    "    image = cv.merge([l_channel, ab_channel])\n",
    "    image = np.clip(image, 0, 1)\n",
    "    image *= 255\n",
    "    image = image.astype(np.uint8)\n",
    "    image = cv.cvtColor(image, cv.COLOR_LAB2RGB)\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(directory: Path) -> Tuple:\n",
    "    \"\"\"\n",
    "    Extract features (L channel) and labels (ab channels)\n",
    "\n",
    "    Args:\n",
    "        directory (Path): folder with images dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple: x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    pathnames = list(directory.iterdir())\n",
    "    x, y = [], []\n",
    "    for pathname in pathnames:\n",
    "        l_channel, ab_channel = preprocess_image(pathname)\n",
    "        x.append(l_channel)\n",
    "        y.append(ab_channel)\n",
    "    features = np.array(x)\n",
    "    labels = np.array(y)\n",
    "    # train(70)/val(15)/test(15)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.15, random_state=42\n",
    "    )\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def plot_images(image_dict: Dict[str, np.ndarray]):\n",
    "    \"\"\"\n",
    "    Show the given images (1-4) side by side.\n",
    "\n",
    "    Args:\n",
    "        image_dict (Dict[str, np.ndarray]): title, image\n",
    "    \"\"\"\n",
    "\n",
    "    keys = list(image_dict.keys())\n",
    "    n = len(image_dict)\n",
    "    assert n <= 4, \"Limit of 4 images side by side\"\n",
    "    fig, images = plt.subplots(1, n)\n",
    "    fig.set_size_inches(n * 5, 5)\n",
    "    if n == 1:\n",
    "        images = [images]\n",
    "    for index, im in enumerate(images):\n",
    "        im.axis(\"off\")\n",
    "        title = keys[index]\n",
    "        im.set_title(title)\n",
    "        image = image_dict[title]\n",
    "        if image.ndim != 3:\n",
    "            im.imshow(image, cmap=\"gray\")\n",
    "        else:\n",
    "            im.imshow(image)\n",
    "\n",
    "\n",
    "def create_model_colorization(model_func):\n",
    "    \"\"\"\n",
    "    Define the colorization model\n",
    "\n",
    "    Args:\n",
    "        model_func (_type_): a function that create a TF model with different testing layer\n",
    "\n",
    "    Returns:\n",
    "        _type_: a TF colorization model with layers\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "    output_layer = model_func(input_layer)\n",
    "    model_colorization = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model_colorization.summary()\n",
    "    return model_colorization\n",
    "\n",
    "\n",
    "def train_pipeline(\n",
    "    model_func, compile_func, fit_func, features: np.ndarray, labels: np.ndarray\n",
    "):\n",
    "    \"\"\"\n",
    "    A pipeline to apply a training step. A model creation, compilation and fit from training data and labels\n",
    "\n",
    "    Args:\n",
    "        model_func (_type_): a function that create a TF model with different testing layers\n",
    "        compile_func (_type_): a function that compile a TF model with different testing optimizers, losses and metrics\n",
    "        fit_func (_type_): a function that fit a TF model with different testing parameters like epochs\n",
    "        data (np.ndarray): training data\n",
    "        labels (np.ndarray): training labels\n",
    "\n",
    "    Returns:\n",
    "        _type_: a trained TF colorization model\n",
    "    \"\"\"\n",
    "    model = create_model_colorization(model_func)\n",
    "    compile_func(model)\n",
    "    fit_func(model, features, labels)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_ab_channel(l_channel: np.ndarray, model) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Color prediction (ab_channel) from an image (using the grayscale L*) created by the model\n",
    "\n",
    "    Args:\n",
    "        l_channel (np.ndarray): input\n",
    "        model (_type_): a TF model for colorization\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: a new predicted ab channel\n",
    "    \"\"\"\n",
    "    grayscale = l_channel.reshape(1, HEIGHT, WIDTH, 1)\n",
    "    ab_prediction = model.predict(grayscale, batch_size=BATCH)\n",
    "    ab_prediction = ab_prediction.reshape(HEIGHT, WIDTH, 2)\n",
    "    return ab_prediction\n",
    "\n",
    "\n",
    "def test_eval(model, features: np.ndarray, labels: np.ndarray):\n",
    "    \"\"\"\n",
    "    Evaluate the model with testing data and labels\n",
    "\n",
    "    Args:\n",
    "        model (_type_): a trained TF colorization model\n",
    "        features (np.ndarray): testing features\n",
    "        labels (np.ndarray): testing labels\n",
    "    \"\"\"\n",
    "    model.evaluate(features, labels, batch_size=BATCH)\n",
    "\n",
    "\n",
    "def save_my_model(model, name: str):\n",
    "    \"\"\"\n",
    "    Save a model into the folder MODELS_DIR\n",
    "\n",
    "    Args:\n",
    "        model (_type_): a trained model\n",
    "        name (str): model name\n",
    "    \"\"\"\n",
    "    model.save(f\"{MODELS_DIR}/{name}.h5\")\n",
    "\n",
    "\n",
    "def load_my_model(name: str):\n",
    "    \"\"\"\n",
    "    Load a model from the folder MODELS_DIR\n",
    "\n",
    "    Args:\n",
    "        name (str): model name\n",
    "\n",
    "    Returns:\n",
    "        _type_: a trained model\n",
    "    \"\"\"\n",
    "    model = load_model(f\"{MODELS_DIR}/{name}.h5\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classic(input_layer):\n",
    "    model_ = Conv2D(16, (3, 3), padding=\"same\", strides=1)(input_layer)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    # model_ = Conv2D(64,(3,3), activation='relu',strides=1)(model_)\n",
    "    model_ = Conv2D(32, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(model_)\n",
    "    model_ = Conv2D(64, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(model_)\n",
    "    model_ = Conv2D(128, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = Conv2D(256, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = UpSampling2D((2, 2))(model_)\n",
    "    model_ = Conv2D(128, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = UpSampling2D((2, 2))(model_)\n",
    "    model_ = Conv2D(64, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    # model_ = BatchNormalization()(model_)\n",
    "    concat_ = concatenate([model_, input_layer])\n",
    "    model_ = Conv2D(64, (3, 3), padding=\"same\", strides=1)(concat_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    model_ = BatchNormalization()(model_)\n",
    "    model_ = Conv2D(32, (3, 3), padding=\"same\", strides=1)(model_)\n",
    "    model_ = LeakyReLU()(model_)\n",
    "    # model_ = BatchNormalization()(model_)\n",
    "    # NOTE: BECAUSE MY VALUES ARE BETWEEN 0-1,  model_ = Conv2D(2, (3, 3), activation=\"sigmoid\", padding=\"same\", strides=1)(model_)\n",
    "    model_ = Conv2D(2, (3, 3), activation=\"tanh\", padding=\"same\", strides=1)(model_)\n",
    "    return model_\n",
    "\n",
    "\n",
    "def model_basic_conv(input_layer):\n",
    "    model = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(\n",
    "        input_layer\n",
    "    )\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv_sampling(input_layer):\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_adam_mse(model):\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "\n",
    "def compile_adam_rmse(model):\n",
    "    model.compile(optimizer=\"adam\", loss=\"rmse\")\n",
    "\n",
    "\n",
    "def compile_adam_mae(model):\n",
    "    model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "\n",
    "\n",
    "def compile_rmsprop_mse(model):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "\n",
    "\n",
    "def compile_rmsprop_rmse(model):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"rmse\")\n",
    "\n",
    "\n",
    "def compile_rmsprop_mae(model):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mae\")\n",
    "\n",
    "\n",
    "def fit_callbacks(model, features, labels):\n",
    "    # train(70)/val(15)/test(15)\n",
    "    model.fit(\n",
    "        features,\n",
    "        labels,\n",
    "        epochs=50,\n",
    "        validation_split=0.15,\n",
    "        batch_size=BATCH,\n",
    "        callbacks=CALLBACKS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing dataset from \"./images\"\n",
    "x_train, x_test, y_train, y_test = load_dataset(IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "model_name = \"test\"\n",
    "model_layers = model_basic_conv\n",
    "model_compile = compile_adam_mse\n",
    "model_fit = fit_callbacks\n",
    "\n",
    "# Model construction\n",
    "model = train_pipeline(model_layers, model_compile, model_fit, x_train, y_train)\n",
    "save_my_model(model, model_name)\n",
    "print(\"\\n\\nTEST\\n----\")\n",
    "test_eval(model, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some results images\n",
    "START = 20\n",
    "N_IMAGES = 2\n",
    "for n_jpg in range(START, START + N_IMAGES):\n",
    "    image_path = Path(IMAGES_DIR, f\"{n_jpg}.jpg\")\n",
    "\n",
    "    name_1 = \"test\"\n",
    "    name_2 = \"test\"\n",
    "\n",
    "    model_1 = load_my_model(name_1)\n",
    "\n",
    "    l_channel, ab_channel = preprocess_image(image_path)\n",
    "    new_ab_channel = predict_ab_channel(l_channel, model_1)\n",
    "    original_image = construct_image(l_channel, ab_channel)\n",
    "    new_image = construct_image(l_channel, new_ab_channel)\n",
    "\n",
    "    im_show = {\n",
    "        \"REAL IMAGE\": original_image,\n",
    "        \"GRAYSCALE\": l_channel,\n",
    "        \"PREDICT\": new_image,\n",
    "    }\n",
    "    plot_images(im_show)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
