{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI 4106 - Introduction to Artificial Intelligence - Project W2022\n",
    "\n",
    "Simon Paquette - spaqu044@uottawa.ca - 300044038\n",
    "\n",
    "Image Colorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    ReLU,\n",
    "    RepeatVector,\n",
    "    Reshape,\n",
    "    concatenate,\n",
    "    UpSampling2D,\n",
    "    BatchNormalization,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my gpu: GTX1650 4gb\n",
    "import GPUtil\n",
    "\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for i, gpu in enumerate(GPUs):\n",
    "    print(\n",
    "        \"GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%\".format(\n",
    "            i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil * 100\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDEA\n",
    "\n",
    "- LAB vs LUV\n",
    "- normalize data before\n",
    "- split train/validation/test\n",
    "- tensorboard\n",
    "- callback\n",
    "- checkpoint\n",
    "- conv2d/relu/maxpool2D\n",
    "- random flip\n",
    "- k fold\n",
    "- validation error vs train error\n",
    "- leaky + tanh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = Path(\"images\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "SIZE = (WIDTH, HEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(image_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Open and resized an image from the pathname\n",
    "\n",
    "    Args:\n",
    "        image_path (Path): pathname of the image\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: an opened image\n",
    "    \"\"\"\n",
    "    opened_image = cv.imread(str(image_path), cv.IMREAD_COLOR)\n",
    "    resized_image = cv.resize(opened_image, SIZE)\n",
    "    image = resized_image.astype(\"uint8\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_images(image_dict: dict):\n",
    "    \"\"\"\n",
    "    Show the given images (1-4) side by side. \n",
    "\n",
    "    Args:\n",
    "        image_dict (dict): key: title, value: image\n",
    "    \"\"\"\n",
    "    keys = list(image_dict.keys())\n",
    "    n = len(image_dict)\n",
    "    assert n <= 4, \"Limit of 4 images side by side\"\n",
    "    fig, images = plt.subplots(1, n)\n",
    "    fig.set_size_inches(n * 5, 5)\n",
    "    if n == 1:\n",
    "        images = [images]\n",
    "    for index, im in enumerate(images):\n",
    "        im.axis(\"off\")\n",
    "        title = keys[index]\n",
    "        im.set_title(title)\n",
    "        image = image_dict[title]\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        im.imshow(image)\n",
    "\n",
    "\n",
    "def bgr_to_l_ab_channels(bgr_image: np.ndarray) -> \"tuple[np.ndarray, np.ndarray]\":\n",
    "    \"\"\"\n",
    "    From a bgr image, convert to the l* and a*b* channels\n",
    "\n",
    "    Args:\n",
    "        bgr_image (np.ndarray): an opened bgr image\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: the l* channel and the ab* channel\n",
    "    \"\"\"\n",
    "    lab_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv.split(lab_image)\n",
    "    ab_channel = cv.merge([a_channel, b_channel])\n",
    "    return (l_channel, ab_channel)\n",
    "\n",
    "\n",
    "def l_ab_channels_to_bgr(l_channel: np.ndarray, ab_channel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a bgr image from merging a l* channel and a a*b* channel\n",
    "\n",
    "    Args:\n",
    "        l_channel (np.ndarray): l* channel\n",
    "        ab_channel (np.ndarray): a*b* channel\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: an opened bgr image\n",
    "    \"\"\"\n",
    "    merged_image = cv.merge([l_channel, ab_channel])\n",
    "    bgr_image = cv.cvtColor(merged_image, cv.COLOR_LAB2BGR)\n",
    "    return bgr_image\n",
    "\n",
    "\n",
    "def counter_ndarray(array: np.ndarray) -> OrderedDict:\n",
    "    \"\"\"\n",
    "    Helper function:\n",
    "    Apply a counter to an array to evaluate the distribution of all pixel values\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray): an numpy array\n",
    "\n",
    "    Returns:\n",
    "        OrderedDict: the dict of a counter\n",
    "    \"\"\"\n",
    "    flat = array.flatten()\n",
    "    counts = dict(Counter(flat))\n",
    "    ordered = OrderedDict(sorted(counts.items()))\n",
    "    return ordered\n",
    "\n",
    "\n",
    "def get_train_test_from_dir(images_dir: Path) -> tuple:\n",
    "    \"\"\"\n",
    "    Get data and labels for training and testing\n",
    "\n",
    "    Args:\n",
    "        images_dir (Path): pathname directory containing all the images\n",
    "\n",
    "    Returns:\n",
    "        tuple: x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    pathnames = list(images_dir.iterdir())\n",
    "    x_image, y_image = [], []\n",
    "    for pathname in pathnames:\n",
    "        image = open_image(pathname)\n",
    "        l_channel, ab_channel = bgr_to_l_ab_channels(image)\n",
    "        x_image.append(l_channel)\n",
    "        y_image.append(ab_channel)\n",
    "    data = np.array(x_image)\n",
    "    labels = np.array(y_image)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, labels, test_size=0.2, shuffle=True\n",
    "    )\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def predict_image(array: np.ndarray, model, batch_size: int = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Color prediction from an image (using the grayscale) created by the model\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray): an opened image\n",
    "        model (_type_): a TF model for colorization\n",
    "        batch_size (int, optional): bacth size to predict. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: a new predicted colored image\n",
    "    \"\"\"\n",
    "    l_channel, ab_channel = bgr_to_l_ab_channels(array)\n",
    "    grayscale = l_channel.reshape(1, HEIGHT, WIDTH, 1)\n",
    "    ab_prediction = model.predict(grayscale, batch_size=batch_size)\n",
    "    ab_prediction = ab_prediction.reshape(HEIGHT, WIDTH, 2)\n",
    "    ab_prediction[ab_prediction < 0] = 0\n",
    "    ab_prediction = ab_prediction.astype(\"uint8\")\n",
    "    new_image = l_ab_channels_to_bgr(l_channel, ab_prediction)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def create_model_colorization(model_func):\n",
    "    \"\"\"\n",
    "    Define the colorization model\n",
    "\n",
    "    Args:\n",
    "        model_func (_type_): a function that create a TF model with different testing layer\n",
    "\n",
    "    Returns:\n",
    "        _type_: a TF colorization model with layers\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(HEIGHT, WIDTH, 1))\n",
    "    output_layer = model_func(input_layer)\n",
    "    model_colorization = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model_colorization.summary()\n",
    "    return model_colorization\n",
    "\n",
    "\n",
    "def train_pipeline(\n",
    "    model_func, compile_func, fit_func, data: np.ndarray, labels: np.ndarray\n",
    "):\n",
    "    \"\"\"\n",
    "    A pipeline to apply a training step. A model creation, compilation and fit from training data and labels\n",
    "\n",
    "    Args:\n",
    "        model_func (_type_): a function that create a TF model with different testing layers\n",
    "        compile_func (_type_): a function that compile a TF model with different testing optimizers, losses and metrics\n",
    "        fit_func (_type_): a function that fit a TF model with different testing parameters like epochs\n",
    "        data (np.ndarray): training data\n",
    "        labels (np.ndarray): training labels\n",
    "\n",
    "    Returns:\n",
    "        _type_: a trained TF colorization model\n",
    "    \"\"\"\n",
    "    model = create_model_colorization(model_func)\n",
    "    compile_func(model)\n",
    "    fit_func(model, data, labels)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_eval(model, data: np.ndarray, labels: np.ndarray, batch_size: int = None):\n",
    "    \"\"\"\n",
    "    Evaluate the model with testing data and labels\n",
    "\n",
    "    Args:\n",
    "        model (_type_): a trained TF colorization model\n",
    "        data (np.ndarray): testing data\n",
    "        labels (np.ndarray): testing labels\n",
    "        batch_size (int, optional): bacth size to evaluate. Defaults to None.\n",
    "    \"\"\"\n",
    "    model.evaluate(data, labels, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def save_my_model(model, name: str):\n",
    "    \"\"\"\n",
    "    Save a model into the folder MODELS_DIR\n",
    "\n",
    "    Args:\n",
    "        model (_type_): a trained model\n",
    "        name (str): model name\n",
    "    \"\"\"\n",
    "    model.save(f\"{MODELS_DIR}/{name}.h5\")\n",
    "\n",
    "\n",
    "def load_my_model(name: str):\n",
    "    \"\"\"\n",
    "    Load a model from the folder MODELS_DIR\n",
    "\n",
    "    Args:\n",
    "        name (str): model name\n",
    "\n",
    "    Returns:\n",
    "        _type_: a trained model\n",
    "    \"\"\"\n",
    "    model = load_model(f\"{MODELS_DIR}/{name}.h5\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_basic_conv(input_layer):\n",
    "    model = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(\n",
    "        input_layer\n",
    "    )\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_conv_sampling(input_layer):\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", strides=2)(model)\n",
    "    model = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\")(model)\n",
    "    model = UpSampling2D((2, 2))(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_rev_conv(input_layer):\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(\n",
    "        input_layer\n",
    "    )\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    model = Conv2D(2, (3, 3), activation=\"relu\", padding=\"same\", strides=1)(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_adam(model):\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "\n",
    "def compile_rmsprop(model):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "\n",
    "\n",
    "def fit_2(model, data, labels):\n",
    "    model.fit(data, labels, epochs=2, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "def fit_10(model, data, labels):\n",
    "    model.fit(data, labels, epochs=10, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "def fit_25(model, data, labels):\n",
    "    model.fit(data, labels, epochs=25, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "def fit_50(model, data, labels):\n",
    "    model.fit(data, labels, epochs=50, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_train_test_from_dir(IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"rev_conv_adam_10\"\n",
    "model_layers = model_rev_conv\n",
    "model_compile = compile_adam\n",
    "model_fit = fit_10\n",
    "\n",
    "print(\"TRAIN\")\n",
    "model = train_pipeline(model_layers, model_compile, model_fit, x_train, y_train)\n",
    "save_my_model(model, model_name)\n",
    "print(\"\\n\\nTEST\\n----\")\n",
    "test_eval(model, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jpg = 6000\n",
    "image_path = Path(IMAGES_DIR, f\"{n_jpg}.jpg\")\n",
    "\n",
    "name_1 = \"basic_conv_adam_2\"\n",
    "name_2 = \"rev_conv_adam_10\"\n",
    "\n",
    "model_1 = load_my_model(name_1)\n",
    "model_2 = load_my_model(name_2)\n",
    "raw_image = open_image(image_path)\n",
    "grayscale, _ = bgr_to_l_ab_channels(raw_image)\n",
    "new_image_1 = predict_image(raw_image, model_1)\n",
    "new_image_2 = predict_image(raw_image, model_2)\n",
    "\n",
    "im_show = {\n",
    "    \"REAL IMAGE\": raw_image,\n",
    "    \"GRAYSCALE\": grayscale,\n",
    "    \"PREDICT 1\": new_image_1,\n",
    "    \"PREDICT 2\": new_image_2,\n",
    "}\n",
    "plot_images(im_show)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35741477ea2a9b41b2c01aa36d7bff5cc0634811e7065b3f8331de360789210c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
